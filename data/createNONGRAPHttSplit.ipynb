{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.3e+01 1.0e+04 1.0e+04 ... 2.3e+02 1.0e+04 1.0e+04]\n",
      " [1.0e+04 1.0e+04 1.0e+04 ... 2.0e+03 1.0e+04 1.0e+04]\n",
      " [1.0e+04 7.5e+01 1.9e+00 ... 1.2e+02 2.3e+00 1.0e+04]\n",
      " ...\n",
      " [1.0e+04 1.3e+01 7.7e+02 ... 9.8e+02 5.1e+03 1.0e+04]\n",
      " [6.3e+01 6.3e+01 6.9e+03 ... 5.2e+00 1.0e+04 3.5e+03]\n",
      " [1.0e+04 1.0e+04 1.0e+04 ... 1.9e+03 4.4e+03 1.0e+04]]\n",
      "[[7.36653154 5.         5.         ... 6.63827216 5.         5.        ]\n",
      " [5.         5.         5.         ... 5.69897    5.         5.        ]\n",
      " [5.         7.12493874 8.7212464  ... 6.92081875 8.63827216 5.        ]\n",
      " ...\n",
      " [5.         7.88605665 6.11350927 ... 6.00877392 5.29242982 5.        ]\n",
      " [7.20065945 7.20065945 5.16115091 ... 8.28399666 5.         5.45593196]\n",
      " [5.         5.         5.         ... 5.7212464  5.35654732 5.        ]]\n",
      "CSV written to davis_nonGraph_train.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "\n",
    "def create_affinity_csv(\n",
    "    dataset_path: str,\n",
    "    output_csv: str,\n",
    "    use_train_test_split: bool = False,\n",
    "    fold_type: str = 'train',  # or 'test'\n",
    "    dataset_name: str = 'davis'  \n",
    "):\n",
    "    # Load ligands and proteins with order preserved\n",
    "    ligands = json.load(open(f\"{dataset_path}/ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
    "    drugs = list(ligands.values())\n",
    "    drug_ids = list(ligands.keys())\n",
    "\n",
    "    proteins = json.load(open(f\"{dataset_path}/proteins.txt\"), object_pairs_hook=OrderedDict)\n",
    "    targets = list(proteins.values())\n",
    "    target_ids = list(proteins.keys())\n",
    "\n",
    "    # Load affinity matrix\n",
    "    affinity = pickle.load(open(f\"{dataset_path}/Y\", \"rb\"), encoding='latin1')\n",
    "    if dataset_name.lower() == 'davis':\n",
    "        print(affinity)\n",
    "        affinity = -np.log10(np.array(affinity) / 1e9)\n",
    "        print(affinity)\n",
    "    else:\n",
    "        affinity = np.array(affinity)\n",
    "\n",
    "    # Identify all non-NaN pairs\n",
    "    all_rows, all_cols = np.where(~np.isnan(affinity))\n",
    "\n",
    "    if use_train_test_split:\n",
    "        if fold_type == 'train':\n",
    "            folds = json.load(open(f\"{dataset_path}/folds/train_fold_setting1.txt\"))\n",
    "        elif fold_type == 'test':\n",
    "            folds = json.load(open(f\"{dataset_path}/folds/test_fold_setting1.txt\"))\n",
    "        else:\n",
    "            raise ValueError(\"fold_type must be 'train' or 'test'\")\n",
    "\n",
    "        if any(isinstance(el, list) for el in folds):\n",
    "            folds = [idx for sublist in folds for idx in sublist]\n",
    "\n",
    "        rows, cols = all_rows[folds], all_cols[folds]\n",
    "    else:\n",
    "        rows, cols = all_rows, all_cols\n",
    "\n",
    "    # Write CSV\n",
    "    with open(output_csv, 'w') as f:\n",
    "        f.write(\"drug_id,compound_iso_smiles,protein_id,target_sequence,affinity\\n\")\n",
    "        for i in range(len(rows)):\n",
    "            row = rows[i]\n",
    "            col = cols[i]\n",
    "            smi = drugs[row]\n",
    "            seq = targets[col]\n",
    "            aff = affinity[row, col]\n",
    "            drug_id = drug_ids[row]\n",
    "            target_id = target_ids[col]\n",
    "            f.write(f\"{drug_id},{smi},{target_id},{seq},{aff}\\n\")\n",
    "\n",
    "    print(f\"CSV written to {output_csv}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "create_affinity_csv(\n",
    "    dataset_path=\"davis\",\n",
    "    output_csv=\"davis_nonGraph_train.csv\",\n",
    "    use_train_test_split=True,  # set to True if you want only train or test data\n",
    "    fold_type=\"train\",\n",
    "    dataset_name=\"davis\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV written to pharos_with_ids.csv\n",
      "Matched: 495 pairs, Unmatched: 0 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def create_affinity_csv_from_pharos_csv(\n",
    "    pharos_csv: str,\n",
    "    dataset_path: str,\n",
    "    output_csv: str\n",
    "):\n",
    "    # Load ligands and proteins with order preserved\n",
    "    ligands = json.load(open(f\"{dataset_path}/ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
    "    proteins = json.load(open(f\"{dataset_path}/proteins.txt\"), object_pairs_hook=OrderedDict)\n",
    "\n",
    "    # Create reverse lookup: SMILES → ID, sequence → ID\n",
    "    smiles_to_id = {v: k for k, v in ligands.items()}\n",
    "    sequence_to_id = {v: k for k, v in proteins.items()}\n",
    "\n",
    "    matched = 0\n",
    "    unmatched = 0\n",
    "\n",
    "    with open(pharos_csv, newline='') as infile, open(output_csv, 'w', newline='') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow([\"drug_id\", \"compound_iso_smiles\", \"protein_id\", \"target_sequence\", \"affinity\"])\n",
    "\n",
    "        for row in reader:\n",
    "            smi = row[\"compound_iso_smiles\"]\n",
    "            seq = row[\"target_sequence\"]\n",
    "            aff = row[\"affinity\"]\n",
    "\n",
    "            drug_id = smiles_to_id.get(smi)\n",
    "            target_id = sequence_to_id.get(seq)\n",
    "\n",
    "            if drug_id is not None and target_id is not None:\n",
    "                writer.writerow([drug_id, smi, target_id, seq, aff])\n",
    "                matched += 1\n",
    "            else:\n",
    "                unmatched += 1\n",
    "\n",
    "    print(f\"CSV written to {output_csv}\")\n",
    "    print(f\"Matched: {matched} pairs, Unmatched: {unmatched} rows\")\n",
    "\n",
    "# Example usage:\n",
    "create_affinity_csv_from_pharos_csv(\n",
    "    pharos_csv=\"../pharos.csv\",\n",
    "    dataset_path=\"pharos\",\n",
    "    output_csv=\"pharos_with_ids.csv\"\n",
    ")\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV written to davis_b_test_with_ids.csv\n",
      "Matched: 68 pairs, Unmatched: 0 rows\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "import csv\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "def canonicalize_smiles(smiles: str) -> str:\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    return Chem.MolToSmiles(mol, canonical=True) if mol else None\n",
    "\n",
    "def create_affinity_csv(input_csv: str, dataset_path: str, output_csv: str):\n",
    "    ligands = json.load(open(f\"{dataset_path}/ligands_can.txt\"), object_pairs_hook=OrderedDict)\n",
    "    proteins = json.load(open(f\"{dataset_path}/proteins.txt\"), object_pairs_hook=OrderedDict)\n",
    "\n",
    "    # Use canonical SMILES for lookup keys\n",
    "    smiles_to_id = {canonicalize_smiles(v): k for k, v in ligands.items()}\n",
    "    sequence_to_id = {v.strip(): k for k, v in proteins.items()}\n",
    "\n",
    "    matched = 0\n",
    "    unmatched = 0\n",
    "\n",
    "    with open(input_csv, newline='', encoding='utf-8') as infile, open(output_csv, 'w', newline='', encoding='utf-8') as outfile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow([\"drug_id\", \"compound_iso_smiles\", \"protein_id\", \"target_sequence\", \"affinity\"])\n",
    "\n",
    "        for row in reader:\n",
    "            smi_raw = row[\"compound_iso_smiles\"].strip()\n",
    "            seq = row[\"target_sequence\"].strip()\n",
    "            aff = row.get(\"affinity\", \"\").strip()\n",
    "\n",
    "            smi = canonicalize_smiles(smi_raw)\n",
    "            drug_id = smiles_to_id.get(smi)\n",
    "            target_id = sequence_to_id.get(seq)\n",
    "\n",
    "            if drug_id is not None and target_id is not None:\n",
    "                writer.writerow([drug_id, smi_raw, target_id, seq, aff])\n",
    "                matched += 1\n",
    "            else:\n",
    "                unmatched += 1\n",
    "                print(f\"Unmatched row: Canonical SMILES={smi}, Seq={seq}\")\n",
    "\n",
    "    print(f\"CSV written to {output_csv}\")\n",
    "    print(f\"Matched: {matched} pairs, Unmatched: {unmatched} rows\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "create_affinity_csv(\n",
    "    input_csv=\"../davis_blinding/data/davis_b_test.csv\",\n",
    "    dataset_path=\"davis\",\n",
    "    output_csv=\"davis_b_test_with_ids.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
