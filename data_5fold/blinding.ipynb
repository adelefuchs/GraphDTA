{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20% blinding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0: 76 proteins blinded.\n",
      "  Train set -> data/davis_b3_train_1.csv\n",
      "  Test set  -> data/davis_b3_test_1.csv\n",
      "\n",
      "Fold 1: 76 proteins blinded.\n",
      "  Train set -> data/davis_b3_train_2.csv\n",
      "  Test set  -> data/davis_b3_test_2.csv\n",
      "\n",
      "Fold 2: 76 proteins blinded.\n",
      "  Train set -> data/davis_b3_train_3.csv\n",
      "  Test set  -> data/davis_b3_test_3.csv\n",
      "\n",
      "Fold 3: 76 proteins blinded.\n",
      "  Train set -> data/davis_b3_train_4.csv\n",
      "  Test set  -> data/davis_b3_test_4.csv\n",
      "\n",
      "Fold 4: 75 proteins blinded.\n",
      "  Train set -> data/davis_b3_train_5.csv\n",
      "  Test set  -> data/davis_b3_test_5.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Load the original datasets\n",
    "train_df = pd.read_csv(\"data/davis_b3_train.csv\")\n",
    "test_df = pd.read_csv(\"data/davis_b3_test.csv\")\n",
    "\n",
    "# Combine train and test into one dataframe\n",
    "combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "# Extract all unique proteins\n",
    "all_proteins = list(combined_df[\"target_sequence\"].unique())\n",
    "\n",
    "# Shuffle proteins\n",
    "random.shuffle(all_proteins)\n",
    "\n",
    "# Define number of folds\n",
    "num_folds = 5\n",
    "proteins_per_fold = len(all_proteins) // num_folds\n",
    "leftover = len(all_proteins) % num_folds\n",
    "\n",
    "# Distribute proteins into folds\n",
    "folds = []\n",
    "start_idx = 0\n",
    "for fold in range(num_folds):\n",
    "    end_idx = start_idx + proteins_per_fold + (1 if fold < leftover else 0)\n",
    "    folds.append(all_proteins[start_idx:end_idx])\n",
    "    start_idx = end_idx\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Create and save folds\n",
    "for fold_idx, proteins_to_blind in enumerate(folds):\n",
    "    proteins_to_blind = set(proteins_to_blind)\n",
    "\n",
    "    # Separate blinded and non-blinded interactions\n",
    "    test_df_blinded = combined_df[combined_df[\"target_sequence\"].isin(proteins_to_blind)]\n",
    "    train_df_blinded = combined_df[~combined_df[\"target_sequence\"].isin(proteins_to_blind)]\n",
    "\n",
    "    # Save the datasets\n",
    "    train_file = os.path.join(output_dir, f\"davis_b3_train_{fold_idx+1}.csv\")\n",
    "    test_file = os.path.join(output_dir, f\"davis_b3_test_{fold_idx+1}.csv\")\n",
    "    train_df_blinded.to_csv(train_file, index=False)\n",
    "    test_df_blinded.to_csv(test_file, index=False)\n",
    "\n",
    "    print(f\"Fold {fold_idx}: {len(proteins_to_blind)} proteins blinded.\")\n",
    "    print(f\"  Train set -> {train_file}\")\n",
    "    print(f\"  Test set  -> {test_file}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run create_data on each pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processed data found: data/processed/pharos_test.pt, loading ...\n",
      "<class 'torch_geometric.loader.dataloader.DataLoader'>\n",
      "Data(x=[40, 78], edge_index=[2, 86], y=[1], target=[1, 1000], c_size=[1], drug_id='5280', protein_id='Q86TW2')\n",
      "DataBatch(x=[914, 78], edge_index=[2, 1984], y=[32], target=[32, 1000], c_size=[32], drug_id=[32], protein_id=[32], batch=[914], ptr=[33])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch_geometric.loader import DataLoader\n",
    "from models.ginconv import GINConvNet\n",
    "from utils import TestbedDataset  # Adjust the import path as needed\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the validation dataset\n",
    "validation_data = TestbedDataset(root='data', dataset='pharos_test')\n",
    "\n",
    "# Create a DataLoader for the validation dataset\n",
    "validation_loader = DataLoader(validation_data, batch_size=32, shuffle=False)\n",
    "print(type(validation_loader))\n",
    "\n",
    "print(validation_data[0])\n",
    "\n",
    "for batch in validation_loader:\n",
    "    print(batch)  # This will print the batch structure, useful for debugging\n",
    "    break  # Print only the first batch to inspect structure\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
